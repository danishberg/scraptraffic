#!/usr/bin/env python
# Scraptraffic Voice Bot â€“ GPTâ€‘4o Audio Preview (GradioÂ 4)   24Â AprÂ 2025

from __future__ import annotations
import os, base64, tempfile, threading, logging
from typing import List, Dict

import gradio as gr
from dotenv import load_dotenv
from openai import OpenAI

logging.basicConfig(format="%(asctime)s %(levelname)s %(message)s",
                    level=logging.INFO)
log = logging.getLogger("voiceâ€‘bot")

load_dotenv()
client = OpenAI()                    # needs OPENAI_API_KEY
MODEL  = "gpt-4o-audio-preview"

SYSTEM_PROMPT = """
Ğ¢Ñ‹Â â€” Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Scraptraffic. Ğ¡Ğ¿Ñ€Ğ¾ÑĞ¸ Ğ³Ğ¾Ñ€Ğ¾Ğ´, Ğ¼ĞµÑ‚Ğ°Ğ»Ğ» Ğ¸ Ğ¾Ğ±ÑŠÑ‘Ğ¼; ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸;
Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¸Ğµ; ĞµÑĞ»Ğ¸ Ñ†ĞµĞ½ÑƒÂ â€” Ğ¿ĞµÑ€ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²ÑŒ; Ğ¿Ğ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹Â â€” Ğ¸Ğ·Ğ²Ğ¸Ğ½Ğ¸ÑÑŒ;
Ğ¿Ğ¾ÑĞ»Ğµ Â«Ğ´Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸ÑÂ» Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ°Ğ¹. Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²ÑƒÑ Ğ·Ğ°ÑĞ²ĞºÑƒ.
""".strip()

# â”€â”€ util: safe audio extraction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def maybe_b64_to_wav(msg) -> str:
    """Return tempâ€‘file path or "" if model produced no audio."""
    if msg and getattr(msg, "audio", None) and msg.audio.data:
        data = base64.b64decode(msg.audio.data)
        tmp  = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        tmp.write(data); tmp.flush()
        return tmp.name
    return ""

# â”€â”€ conversation memory (threadâ€‘safe) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
h_lock = threading.Lock()
history: List[Dict] = []

def reset() -> List[Dict]:
    with h_lock:
        history.clear()
        history.append({"role": "system", "content": SYSTEM_PROMPT})
    log.info("history reset")
    return []

reset()

# â”€â”€ mode switch (adds greeting) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def switch_mode(mode: str):
    reset()
    if mode != "Conversational":
        return [], ""
    greet = "Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ! Ğ’Ñ‹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ğ»Ğ¸ Ğ² Scraptraffic."
    with h_lock:
        history.append({"role": "assistant", "content": greet})

    rsp  = client.chat.completions.create(
        model      = MODEL,
        modalities = ["text", "audio"],
        audio      = {"voice": "alloy", "format": "wav"},
        messages   = history,
    )
    text = rsp.choices[0].message.content or "(speechâ€‘only)"
    wav  = maybe_b64_to_wav(rsp.choices[0].message)     # â† safe
    with h_lock:
        history[-1]["content"] = text
    visible = [{"role": m["role"], "content": m["content"]}
               for m in history if m["role"] != "system"]
    return visible, wav

# â”€â”€ main turn â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_turn(wav_path, mode, chat_state):
    if not wav_path:
        return chat_state, ""

    with h_lock:
        history.append({"role": "user", "content": "", "audio": wav_path})
        msgs = history.copy()

    try:
        rsp = client.chat.completions.create(
            model      = MODEL,
            modalities = ["text", "audio"],
            audio      = {"voice": "alloy", "format": "wav"},
            messages   = msgs,
        )
        bot_text = rsp.choices[0].message.content or "(speechâ€‘only)"
        bot_wav  = maybe_b64_to_wav(rsp.choices[0].message)  # â† safe
    except Exception as exc:
        log.exception("OpenAI error")
        bot_text, bot_wav = f"âš ï¸ {exc}", ""

    with h_lock:
        history.append({"role": "assistant", "content": bot_text})
        chat_state.append({"role": "user",      "content": "(Ğ°ÑƒĞ´Ğ¸Ğ¾)"})
        chat_state.append({"role": "assistant", "content": bot_text})

    if mode == "File Mode":
        bot_wav = ""
    return chat_state, bot_wav

# â”€â”€ Gradio UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CSS = ".gradio-container {font-family: ui-sans-serif, system-ui, sans-serif}"

with gr.Blocks(title="Scraptraffic Voice Bot", css=CSS) as demo:
    gr.Markdown("### ğŸ“Â Scraptraffic Voice Bot (GPTâ€‘4o Audio Preview)")
    mode    = gr.Radio(["File Mode", "Conversational"],
                       value="File Mode", label="Ğ ĞµĞ¶Ğ¸Ğ¼")
    chatbox = gr.Chatbot(type="messages", label="Ğ”Ğ¸Ğ°Ğ»Ğ¾Ğ³", height=380)
    mic     = gr.Audio(sources=["microphone"], type="filepath",
                       label="ğŸ™ï¸Â Holdâ€‘toâ€‘talk")
    answer  = gr.Audio(label="ğŸ¤–Â ĞÑ‚Ğ²ĞµÑ‚", interactive=False, autoplay=True)
    reset_b = gr.Button("ğŸ”„Â Reset")

    mode.change(switch_mode, mode, [chatbox, answer], queue=False)
    mic.stop_recording(run_turn,
                       inputs=[mic, mode, chatbox],
                       outputs=[chatbox, answer])
    reset_b.click(lambda: (reset(), ""), None, [chatbox, answer], queue=False)

if __name__ == "__main__":
    log.info("open  http://127.0.0.1:7860  in your browser")
    demo.launch(server_name="0.0.0.0", server_port=7860)







#!/usr/bin/env python
# Scraptraffic Voice Bot â€“ GPTâ€‘4o Audio Preview (fileâ€‘mode only)
# 25 Apr 2025

import base64
import tempfile
import uuid
import threading
import logging
import pathlib
from typing import List, Dict, Tuple, Optional

import gradio as gr
from dotenv import load_dotenv
from openai import OpenAI

# â”€â”€ logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
)
log = logging.getLogger("scrap-bot")

# â”€â”€ OpenAI init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
client      = OpenAI()
MODEL_AUDIO = "gpt-4o-audio-preview"
MODEL_TEXT  = "gpt-4o"
VOICE       = "alloy"
WHISPER     = "whisper-1"
TTS         = "tts-1"

# â”€â”€ system prompt & history â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """
Ğ¢Ñ‹ â€” Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Scraptraffic. ĞšĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸Ñ‚ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑŒ, ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸:
â€¢ Ğ³Ğ¾Ñ€Ğ¾Ğ´ â€¢ Ğ¼ĞµÑ‚Ğ°Ğ»Ğ» â€¢ Ğ¾Ğ±ÑŠÑ‘Ğ¼ â€¢ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸.
Ğ•ÑĞ»Ğ¸ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ÑÑ‚ Ñ†ĞµĞ½Ñƒ â€” Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ñƒ. ĞŸĞ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ğµ Ñ‚ĞµĞ¼Ñ‹ â€” Ğ¸Ğ·Ğ²Ğ¸Ğ½Ğ¸ÑÑŒ.
ĞŸĞ¾ÑĞ»Ğµ Â«Ğ´Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸ÑÂ» Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ°Ğ¹. Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²ÑƒÑ Ğ·Ğ°ÑĞ²ĞºÑƒ.
""".strip()

H_LOCK  = threading.Lock()
HISTORY: List[Dict] = [{"role": "system", "content": SYSTEM_PROMPT}]
KEEP    = 8  # keep last N user+assistant pairs

def clear_history() -> List[Dict]:
    log.info("Resetting conversation history")
    with H_LOCK:
        HISTORY[:] = HISTORY[:1]
    return []

def trim_history() -> List[Dict]:
    with H_LOCK:
        base = HISTORY[:1]
        tail = HISTORY[1:]
    return base + tail[-(KEEP*2):]

def save_temp_wav(b64: str) -> str:
    data = base64.b64decode(b64)
    fn = pathlib.Path(tempfile.gettempdir()) / f"scrap_{uuid.uuid4().hex}.wav"
    with open(fn, "wb") as f:
        f.write(data)
    log.info(f"WAV written to {fn} ({len(data)} bytes)")
    return str(fn)

def greet() -> Tuple[List[Dict], Optional[str]]:
    log.info("Greeting userâ€¦")
    resp = client.chat.completions.create(
        model      = MODEL_AUDIO,
        modalities = ["text", "audio"],
        audio      = {"voice": VOICE, "format": "wav"},
        messages   = [{"role":"system", "content":SYSTEM_PROMPT}],
    )
    msg = resp.choices[0].message
    text = msg.content or "(speech-only)"
    b64  = getattr(getattr(msg, "audio", None), "data", "")
    wav  = save_temp_wav(b64) if b64 else None

    with H_LOCK:
        HISTORY.append({"role":"assistant","content":text})

    return [m for m in HISTORY if m["role"]!="system"], wav

def talk(mic_wav: str, chat_ui: List[Dict]) -> Tuple[List[Dict], Optional[str]]:
    log.info(f"Received audio file: {mic_wav}")
    if not mic_wav or not pathlib.Path(mic_wav).exists():
        log.warning("Audio file missing")
        return chat_ui, None

    data = pathlib.Path(mic_wav).read_bytes()
    b64  = base64.b64encode(data).decode("ascii")

    # audioâ€‘chat payload must have content=""
    with H_LOCK:
        HISTORY.append({"role":"user", "content":"", "audio":{"data":b64}})

    prompt = trim_history()
    log.info("Sending audioâ†’chat request")
    try:
        resp = client.chat.completions.create(
            model      = MODEL_AUDIO,
            modalities = ["text", "audio"],
            audio      = {"voice": VOICE, "format": "wav"},
            messages   = prompt,
        )
        msg     = resp.choices[0].message
        text    = msg.content or "(speech-only)"
        b64r    = getattr(getattr(msg, "audio", None), "data", "")
        bot_wav = save_temp_wav(b64r) if b64r else None

    except Exception:
        log.exception("Audioâ€‘chat failed; using Whisperâ†’text chatâ†’TTS fallback")

        # 1) Transcribe
        with open(mic_wav, "rb") as f:
            tr = client.audio.transcriptions.create(model=WHISPER, file=f)
        user_text = tr.text
        log.info(f"Whisper: {user_text!r}")

        with H_LOCK:
            HISTORY.append({"role":"user", "content":user_text})

        # 2) Text chat
        text_resp = client.chat.completions.create(
            model    = MODEL_TEXT,
            messages = trim_history(),
        )
        text    = text_resp.choices[0].message.content
        log.info(f"GPTâ€‘4o text reply: {text!r}")

        # 3) TTS
        tts     = client.audio.speech.create(model=TTS, voice=VOICE, input=text)
        bot_wav = save_temp_wav(tts["audio"]["data"])

    with H_LOCK:
        HISTORY.append({"role":"assistant","content":text})

    # update UI
    chat_ui.append({"role":"user",      "content":"(Ğ°ÑƒĞ´Ğ¸Ğ¾)"})
    chat_ui.append({"role":"assistant", "content":text})

    return chat_ui, bot_wav

# â”€â”€ Gradio UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with gr.Blocks(title="Scraptraffic Voice Bot (fileâ€‘mode demo)") as demo:
    gr.Markdown("### ğŸ“ Scraptraffic â€” Ğ¿Ñ€Ğ¸Ñ‘Ğ¼ Ğ»Ğ¾Ğ¼Ğ° (fileâ€‘mode demo)")

    chat  = gr.Chatbot(type="messages", label="Ğ”Ğ¸Ğ°Ğ»Ğ¾Ğ³", height=360)
    mic   = gr.Audio(sources=["microphone"], label="ğŸ™ï¸ Hold to Talk",
                     type="filepath", streaming=False)
    reply = gr.Audio(label="ğŸ¤– ĞÑ‚Ğ²ĞµÑ‚", interactive=False, autoplay=True)
    reset = gr.Button("ğŸ”„ Reset")

    demo.load(fn=greet, inputs=None, outputs=[chat, reply])
    mic.stop_recording(fn=talk, inputs=[mic, chat], outputs=[chat, reply])
    reset.click(fn=lambda: (clear_history(), None),
                inputs=None, outputs=[chat, reply], queue=False)

if __name__ == "__main__":
    log.info("Startingâ€¦ http://127.0.0.1:7860")
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
