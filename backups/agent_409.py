#!/usr/bin/env python3
"""
phone_agent.py â€“ Scraptraffic voice bot for OpenAI Realtime API (v3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Key Improvements:
â€¢ Lower-latency 20 ms frames (instead of 30 ms)
â€¢ Throttled mic-status updates (max 10 Hz)
â€¢ Push-to-talk, dynamic VAD (WebRTC or energy-based)
â€¢ Stronger turn-detection thresholds to avoid background noise
â€¢ Maintains single-turn-at-a-time, no mid-response cuts
â€¢ Dynamic ambient recalibration when idle
â€¢ Async-safe, non-blocking audio I/O
â€¢ Extended websocket connect timeout and retry logic
â€¢ Full error handling & automatic recovery on â€œactive responseâ€ races
"""

from __future__ import annotations
import argparse
import asyncio
import os
import sys
import time
import threading

import numpy as np
import sounddevice as sd
from pynput import keyboard

# â”€â”€ Monkey-patch websockets to extend connect timeout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import websockets
from websockets.client import connect as _ws_orig_connect

def _ws_connect(uri, *args, open_timeout: float = 60.0, **kwargs):
    return _ws_orig_connect(uri, *args, open_timeout=open_timeout, **kwargs)

websockets.connect = _ws_connect

from openai_realtime_client import RealtimeClient, TurnDetectionMode

# â”€â”€ Optional WebRTC-VAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    import webrtcvad  # type: ignore
    HAVE_WEBRTC = True
except ModuleNotFoundError:
    HAVE_WEBRTC = False

# â”€â”€ Audio & VAD parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAMPLE_RATE            = 16_000
FRAME_MS               = 20                          # smaller frame for lower latency
FRAME_SAMPLES          = SAMPLE_RATE * FRAME_MS // 1_000

START_SPEECH_FRAMES    = 200  // FRAME_MS            # ~200 ms of speech to start
MIN_UTTERANCE_FRAMES   = 600  // FRAME_MS            # ~600 ms total to send
END_SILENCE_FRAMES     = 2000 // FRAME_MS            # ~2000 ms of silence to end

CALIBRATE_SEC          = 1.5
ENERGY_MULT            = 4.0
ENERGY_OFFSET          = 0.003

OUTPUT_SR              = 24_000                      # assistant audio

SYSTEM_PROMPT = """
Ğ¢Ğ²Ğ¾Ñ Ñ€Ğ¾Ğ»ÑŒ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸ĞºĞ° - ÑÑ‚Ğ¾ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ»Ğ¸Ğ½Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¸ĞµĞ¼Ñƒ Ğ·Ğ²Ğ¾Ğ½ĞºĞ¾Ğ² Ğ² ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ Scraptraffic, Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ÑÑ‰ÑƒÑÑÑ Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ¾Ğ¼ Ğ¼ĞµÑ‚Ğ°Ğ»Ğ»Ğ¾Ğ»Ğ¾Ğ¼Ğ°. Ğ¡ĞºĞ¾Ñ€ĞµĞµ Ğ²ÑĞµĞ³Ğ¾ Ğ²Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹ Ğ·Ğ²Ğ¾Ğ½Ğ¾Ğº Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ñ‚ Ñ‚Ğ¾Ğ³Ğ¾, ĞºÑ‚Ğ¾ Ñ…Ğ¾Ñ‡ĞµÑ‚ ÑĞ´Ğ°Ñ‚ÑŒ ĞºĞ°ĞºĞ¾Ğ¹-Ñ‚Ğ¾ Ğ¼ĞµÑ‚Ğ°Ğ»Ğ». Ğ’ ÑÑ‚Ğ¾Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ñ‚ĞµĞ±Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚ÑŒ: Ğ¼ĞµÑÑ‚Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ° - Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞ¸Ğ¹ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ñ€Ğ¾Ğ´. \
Ğ¢ĞµĞ±Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ²Ñ‹ÑÑĞ½Ğ¸Ñ‚ÑŒ ĞºĞ°ĞºĞ¾Ğ¹ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ» Ñ…Ğ¾Ñ‚ÑÑ‚ ÑĞ´Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ»Ğ¾Ğ¼, ĞºĞ°ĞºĞ¾Ğ¹ Ğ¾Ğ±ÑŠĞµĞ¼ Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ğ¸, Ğ² ĞºĞ°ĞºĞ¾Ğ¼ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğµ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ», Ğ¸ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ĞºĞ°ĞºĞ¸Ğµ-Ñ‚Ğ¾ Ğ¾ÑĞ¾Ğ±Ñ‹Ğµ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ğ¸. \
Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ ÑĞ¿Ñ€Ğ¾ÑĞ¸ â€” Ğ½Ğµ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² Ğ»Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº, Ñ‡Ñ‚Ğ¾ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ² Ñ‚Ğ¾Ğ¼ Ñ‡Ğ¸ÑĞ»Ğµ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½Ñ‹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°Ğ¼ Ğ½Ğ°ÑˆĞµĞ¹ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ ÑĞµÑ‚Ğ¸ Ğ¿Ğ°Ñ€Ñ‚Ğ½ĞµÑ€Ğ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑĞ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ ĞµĞ¼Ñƒ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ ÑĞ´ĞµĞ»ĞºĞ¸ Ğ¸ Ñ†ĞµĞ½Ñƒ.

Ğ•ÑĞ»Ğ¸ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ¾Ğ±Ğ¸Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñƒ, ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ Ğ¼Ñ‹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğ·Ğ°Ğ¿Ğ»Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ·Ğ° ĞµĞ³Ğ¾ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ», Ñ‚Ğ¾ Ğ²ĞµĞ¶Ğ»Ğ¸Ğ²Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰Ğ¸, Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ÑƒÑ Ñ†ĞµĞ½Ñƒ ÑĞ¼Ğ¾Ğ³ÑƒÑ‚ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ¸Ğ»Ğ¸ Ğ¿Ğ°Ñ€Ñ‚Ğ½ĞµÑ€, Ğ° Ñ‚Ñ‹ ÑĞ²Ğ»ÑĞµÑˆÑŒÑÑ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ğ¼ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ„Ğ¸ĞºÑĞ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ°ÑĞ²ĞºÑƒ, Ğ¸ Ñ‚Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿ĞµÑ€Ğ²Ğ¸Ñ‡Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ. Ğ¡Ğ¾Ğ¾Ğ±Ñ‰Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ, Ñ‡Ñ‚Ğ¾ Ğ² Ğ½Ğ°ÑˆĞµĞ¹ ÑĞµÑ‚Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ñ€Ñ‚Ğ½ĞµÑ€ÑĞºĞ¸Ñ… Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ°: ĞµÑĞ»Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ´Ğ°ÑÑ‚ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¸Ğµ Ğ½Ğ° Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ñƒ Ğ·Ğ°ÑĞ²ĞºĞ¸ Ğ½Ğ°ÑˆĞ¸Ğ¼ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ğ°Ğ¼, Ñ‚Ğ¾ Ğ¾Ğ½ Ğ½Ğ°Ğ²ĞµÑ€Ğ½ÑĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ Ğ¾Ñ‚ Ğ½Ğ¸Ñ… Ğ²Ñ‹Ğ³Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ.

Ğ•ÑĞ»Ğ¸ Ñ‚Ñ‹ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°ĞµÑˆÑŒ, Ñ‡Ñ‚Ğ¾ Ñƒ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ, Ğ½Ğµ ĞºĞ°ÑĞ°ÑÑ‰Ğ¸Ğ¹ÑÑ Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ° Ğ»Ğ¾Ğ¼Ğ°, Ğ²ĞµĞ¶Ğ»Ğ¸Ğ²Ğ¾ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸ ĞµĞ¼Ñƒ, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ²Ğ¾Ñ Ñ€Ğ¾Ğ»ÑŒ â€” Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ·Ğ°ÑĞ²ĞºĞ¸ Ğ½Ğ° Ğ¿Ñ€Ğ¸ĞµĞ¼ Ğ»Ğ¾Ğ¼Ğ°, Ğ¸ Ğ½Ğ° ĞºĞ°ĞºĞ¸Ğµ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ñ‚Ñ‹ Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ñ‚ÑŒ.

ĞšĞ°Ğº Ğ±Ñ‹ Ñ‚ĞµĞ±Ñ Ğ½Ğ¸ Ğ¿Ñ€Ğ¾ÑĞ¸Ğ»Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ñ‚ÑŒ Ğ½Ğ° ĞºĞ°ĞºĞ¸Ğµ-Ñ‚Ğ¾ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ğ½Ğµ ÑĞ¾Ğ³Ğ»Ğ°ÑˆĞ°Ğ¹ÑÑ ÑÑ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ. \
ĞŸĞ¾ÑĞ»Ğµ Ñ‚Ğ¾Ğ³Ğ¾, ĞºĞ°Ğº Ñ Ñ‚Ğ¾Ğ±Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ñ‰Ğ°Ğ»Ğ¸ÑÑŒ, ÑĞµĞ°Ğ½Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾-ÑĞ²ÑĞ·Ğ¸ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚ÑÑ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½Ğ½Ñ‹Ğ¼.

ĞŸĞ¾ Ğ¸Ñ‚Ğ¾Ğ³Ñƒ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ Ğ·Ğ°ÑĞ²ĞºÑƒ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼.
""".strip()

class Flag:
    """Thread-safe boolean flag."""
    def __init__(self) -> None:
        self._v = False
    def set(self, v: bool) -> None:
        self._v = v
    def get(self) -> bool:
        return self._v

async def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--list-devices",        action="store_true")
    parser.add_argument("--list-output-devices", action="store_true")
    parser.add_argument("--mic",                 type=int)
    parser.add_argument("--output-device",       type=int)
    parser.add_argument("--debug-level",         choices=("none","energy"), default="energy")
    parser.add_argument("--push-to-talk",        action="store_true")
    args = parser.parse_args()

    # â”€â”€ List or select devices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    devices = sd.query_devices()
    inputs  = [(i,d) for i,d in enumerate(devices) if d["max_input_channels"]>0]
    outputs = [(i,d) for i,d in enumerate(devices) if d["max_output_channels"]>0]
    if args.list_devices:
        print("Input devices:")
        for i,d in inputs:
            print(f"[{i}] {d['name']}")
        return
    if args.list_output_devices:
        print("Output devices:")
        for i,d in outputs:
            print(f"[{i}] {d['name']}")
        return

    mic_index = args.mic if args.mic is not None else inputs[0][0]
    out_index = args.output_device if args.output_device is not None else sd.default.device[1]
    print(f"âœ”ï¸ Mic #{mic_index}:     {devices[mic_index]['name']}")
    print(f"âœ”ï¸ Speaker #{out_index}: {devices[out_index]['name']}")

    # â”€â”€ Prepare OpenAI client & event flags â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    api_key            = os.getenv("OPENAI_API_KEY") or sys.exit("OPENAI_API_KEY not set")
    loop               = asyncio.get_running_loop()
    speaking           = Flag()      # assistant is playing audio
    awaiting_response  = Flag()      # waiting on assistant to finish
    send_lock          = asyncio.Lock()
    assistant_done_evt = asyncio.Event()
    active_response    = False       # track whether the server still has an open response

    # â”€â”€ PCM output stream â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    out_stream = sd.RawOutputStream(
        samplerate=OUTPUT_SR,
        channels=1,
        dtype="int16",
        blocksize=FRAME_SAMPLES,
        device=out_index,
    )
    out_stream.start()

    def play_audio_safe(pcm: bytes) -> None:
        try:
            out_stream.write(pcm)
        except:
            pass

    # â”€â”€ Energy debug â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def debug_energy(e: float, thr: float):
        print(f"\rEnergy {e:.4f}  thr {thr:.4f}", end="", flush=True)

    # â”€â”€ Event handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _on_audio_start(*_):
        speaking.set(True)

    def _on_audio_end(*_):
        nonlocal active_response
        speaking.set(False)
        if awaiting_response.get():
            awaiting_response.set(False)
            active_response = False
            assistant_done_evt.set()
            print("\nğŸ‘‚ Your turn â€” listening now")

    def _on_response_done(*_):
        nonlocal active_response
        if awaiting_response.get():
            awaiting_response.set(False)
            active_response = False
            assistant_done_evt.set()
            print("\nğŸ‘‚ Your turn â€” listening now")

    def _on_interrupted(*_):
        nonlocal active_response
        speaking.set(False)
        if awaiting_response.get():
            awaiting_response.set(False)
            active_response = False
            assistant_done_evt.set()
            print("\nğŸ‘‚ Your turn â€” listening now")

    # â”€â”€ Initialize OpenAI Realtime client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    client = RealtimeClient(
        api_key             = api_key,
        instructions        = SYSTEM_PROMPT,
        voice               = "alloy",
        turn_detection_mode = TurnDetectionMode.MANUAL,
        on_text_delta       = lambda t: print(f"\nAssistant: {t}", end="", flush=True),
        on_audio_delta      = play_audio_safe,
        extra_event_handlers= {
            "response.audio.delta":  _on_audio_start,
            "response.audio.done":   _on_audio_end,
            "response.done":         _on_response_done,
            "response.interrupted":  _on_interrupted,
        }
    )

    # â”€â”€ Helper: create + auto-recover on â€œalready activeâ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def safe_create_response():
        nonlocal active_response
        # if we think oneâ€™s still open, cancel it first
        if active_response:
            try:
                await client.cancel_response()
            except:
                pass
            active_response = False

        for attempt in (1, 2):
            try:
                active_response = True
                await client.create_response()
                return
            except Exception as e:
                msg = str(e).lower()
                # detect that specific race
                if "conversation_already_has_active_response" in msg and attempt == 1:
                    # clear server-side state & retry once
                    try:
                        await client.cancel_response()
                    except:
                        pass
                    active_response = False
                    continue
                # any other error: give up
                active_response = False
                raise

    # â”€â”€ Quit key handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    keyboard.Listener(
        on_press=lambda k: loop.stop() if getattr(k, "char", "") == "q" else None
    ).start()

    # â”€â”€ Connect with retry on timeout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    retries = 3
    for attempt in range(1, retries+1):
        try:
            print(f"ğŸ”Œ Connecting to server (attempt {attempt}/{retries})â€¦")
            await client.connect()
            break
        except TimeoutError:
            if attempt < retries:
                print("â— Connection timed out, retrying in 5 sâ€¦")
                await asyncio.sleep(5)
            else:
                print("âŒ Unable to connect after retries, exiting.")
                sys.exit(1)

    asyncio.create_task(client.handle_messages())

    # â”€â”€ Initial greeting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ™ï¸ Connected â€“ playing greeting â€¦")
    assistant_done_evt.clear()
    awaiting_response.set(True)
    await safe_create_response()
    await assistant_done_evt.wait()
    print("ğŸ‘‚ Your turn â€” listening now")

    # â”€â”€ VAD setup & initial calibration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if HAVE_WEBRTC:
        vad = webrtcvad.Vad(3)
        print("[INFO] WebRTC VAD enabled, mode=3")
    else:
        print("[INFO] Energy VAD fallback")
        print(f"ğŸ”‡ Calibrating ambient for {CALIBRATE_SEC}sâ€¦")
        amb = sd.rec(int(CALIBRATE_SEC * SAMPLE_RATE),
                     samplerate=SAMPLE_RATE,
                     channels=1,
                     dtype="float32",
                     device=mic_index)
        sd.wait()
        rms = float(np.sqrt((amb[:,0]**2).mean()))
        vad_config = {"threshold": rms * ENERGY_MULT + ENERGY_OFFSET}
        print(f"âœ… Initial threshold: {vad_config['threshold']:.6f}")

        def recalibrate():
            while True:
                time.sleep(60)
                if not speaking.get() and not awaiting_response.get():
                    tmp = sd.rec(int(CALIBRATE_SEC * SAMPLE_RATE),
                                 samplerate=SAMPLE_RATE,
                                 channels=1,
                                 dtype="float32",
                                 device=mic_index)
                    sd.wait()
                    rms2 = float(np.sqrt((tmp[:,0]**2).mean()))
                    vad_config["threshold"] = rms2 * ENERGY_MULT + ENERGY_OFFSET
                    print(f"\nğŸ”„ New threshold: {vad_config['threshold']:.6f}")

        threading.Thread(target=recalibrate, daemon=True).start()

    # â”€â”€ Optional push-to-talk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    talk_pressed = Flag()
    if args.push_to_talk:
        from pynput.keyboard import Key, Listener
        def on_press(k):
            if k == Key.space:
                talk_pressed.set(True)
        def on_release(k):
            if k == Key.space:
                talk_pressed.set(False)
        Listener(on_press=on_press, on_release=on_release).start()
        print("ğŸ¤ Push-to-talk: hold SPACE to speak")

    # â”€â”€ Speech capture & turn logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    in_speech      = False
    voice_frames   = 0
    silence_frames = 0
    buffer         = bytearray()
    last_status    = None
    last_stat_t    = 0.0
    last_send_ts   = 0.0
    DEBOUNCE_SEC   = 0.5

    async def send_utt(data: bytes) -> None:
        nonlocal last_send_ts
        assistant_done_evt.clear()
        awaiting_response.set(True)
        last_send_ts = time.time()
        async with send_lock:
            try:
                await client.stream_audio(data)
                await safe_create_response()
            except Exception as e:
                print(f"\nâ— Error during turn: {e}")
                awaiting_response.set(False)
                speaking.set(False)
                assistant_done_evt.set()
            finally:
                await assistant_done_evt.wait()

    def callback(indata, *_):
        nonlocal in_speech, voice_frames, silence_frames, buffer, last_status, last_stat_t
        now = time.time()

        # block while assistant is speaking or awaiting response
        if speaking.get() or awaiting_response.get():
            return
        if args.push_to_talk and not talk_pressed.get():
            return
        # debounce back-to-back triggers
        if now - last_send_ts < DEBOUNCE_SEC:
            return

        samples = indata[:,0]
        energy  = float(np.sqrt((samples**2).mean()))
        pcm     = (samples * 32767).astype("int16").tobytes()

        if args.debug_level == "energy" and not HAVE_WEBRTC:
            debug_energy(energy, vad_config["threshold"])

        if HAVE_WEBRTC:
            is_voice = vad.is_speech(pcm, SAMPLE_RATE)
        else:
            is_voice = energy > vad_config["threshold"]

        # throttle status updates to 10 Hz
        status = "ğŸ”Š" if is_voice else "ğŸ”ˆ"
        if status != last_status or (now - last_stat_t) > 0.1:
            print(f"\r[{status}]", end="", flush=True)
            last_status, last_stat_t = status, now

        if is_voice:
            voice_frames += 1
            silence_frames = 0
            if not in_speech and voice_frames >= START_SPEECH_FRAMES:
                in_speech = True
                buffer.clear()
                print("\n[ğŸ¤ Recordingâ€¦]")
            if in_speech:
                buffer.extend(pcm)
        else:
            silence_frames += 1
            if not in_speech:
                voice_frames = 0
            elif silence_frames < END_SILENCE_FRAMES:
                buffer.extend(pcm)
            else:
                if in_speech:
                    in_speech = False
                    print("\n[Speech ended]")
                    utter_frames = len(buffer)//2//FRAME_SAMPLES
                    if utter_frames >= MIN_UTTERANCE_FRAMES:
                        asyncio.run_coroutine_threadsafe(
                            send_utt(bytes(buffer)), loop
                        )
                buffer.clear()
                voice_frames = silence_frames = 0

    # â”€â”€ Run the audio loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="float32",
        blocksize=FRAME_SAMPLES,
        device=mic_index,
        callback=callback,
    ):
        print("\nğŸ”´ Ready (press q to quit)â€¦")
        try:
            await asyncio.Future()
        except asyncio.CancelledError:
            pass

    # â”€â”€ Cleanup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    out_stream.stop()
    out_stream.close()
    await client.close()
    print("\nğŸ‘‹ Bye")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        pass
